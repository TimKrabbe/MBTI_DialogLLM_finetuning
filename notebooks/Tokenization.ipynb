{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8c1dadb",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0293ae",
   "metadata": {},
   "source": [
    "# Packages\n",
    "\n",
    "datasets function might need to be revised, in case this is part of the script uploaded to cluster\n",
    "--> depends where the data is coming from, might be able to upload somewhere. If uploaded to HF for example, we can't use load_from_disk, but have to use load_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "890314d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2e3de07",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaefdd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_from_disk(\"../data/mbti_dict\")\n",
    "\n",
    "# raw_train_dataset = raw_datasets[\"train\"]\n",
    "# raw_validation_dataset = raw_datasets[\"validation\"]\n",
    "# raw_test_dataset = raw_datasets[\"test\"]\n",
    "\n",
    "\n",
    "# for running local test\n",
    "small_datasets = raw_datasets.filter(lambda _, indices: indices % 100 == 0, with_indices=True)\n",
    "\n",
    "raw_train_dataset = small_datasets[\"train\"]\n",
    "raw_validation_dataset = small_datasets[\"validation\"]\n",
    "raw_test_dataset = small_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bebae9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'post', '__index_level_0__'],\n",
       "        num_rows: 2965\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'post', '__index_level_0__'],\n",
       "        num_rows: 371\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['label', 'post', '__index_level_0__'],\n",
       "        num_rows: 371\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_datasets\n",
    "#raw_train_dataset.features\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4c23a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f848c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "qwen_checkpoint = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(qwen_checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbfe332c",
   "metadata": {},
   "source": [
    "# Chat-Templates and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82e1d676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i'm extremely irritated of most bugs, like when i was last camping i was a total nervous wreck because of all the horseflies, or when a spider appears descending right above me when i'm relaxing in...\n",
      "{'input_ids': [72, 2776, 9016, 83871, 315, 1429, 22551, 11, 1075, 979, 600, 572, 1537, 32773, 600, 572, 264, 2790, 22596, 35750, 1576, 315, 678, 279, 15223, 53919, 11, 476, 979, 264, 34354, 7952, 43084, 1290, 3403, 752, 979, 600, 2776, 33848, 304, 1112], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "['i', \"'m\", 'Ġextremely', 'Ġirritated', 'Ġof', 'Ġmost', 'Ġbugs', ',', 'Ġlike', 'Ġwhen', 'Ġi', 'Ġwas', 'Ġlast', 'Ġcamping', 'Ġi', 'Ġwas', 'Ġa', 'Ġtotal', 'Ġnervous', 'Ġwreck', 'Ġbecause', 'Ġof', 'Ġall', 'Ġthe', 'Ġhorse', 'flies', ',', 'Ġor', 'Ġwhen', 'Ġa', 'Ġspider', 'Ġappears', 'Ġdescending', 'Ġright', 'Ġabove', 'Ġme', 'Ġwhen', 'Ġi', \"'m\", 'Ġrelaxing', 'Ġin', '...']\n"
     ]
    }
   ],
   "source": [
    "test_sentence = raw_train_dataset[\"post\"][0]\n",
    "print(test_sentence)\n",
    "\n",
    "tokenized_sentence = qwen_tokenizer(test_sentence)\n",
    "print(tokenized_sentence)\n",
    "\n",
    "print(qwen_tokenizer.convert_ids_to_tokens(tokenized_sentence[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cef9c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_to_chatml(data):\n",
    "    \n",
    "    prompt = f\"Your personality Type is {data[\"label\"]}. What is on your mind?\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": data[\"post\"]}\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407ae675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7204fc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06da6f10ff4c4369aa293d968ed19985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2965 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "931b0727d1204828a8e4f091b512c6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/371 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf7462b8bc545dba900e9ba40732c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/371 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'content': 'Your personality Type is 9. What is on your mind?', 'role': 'user'}, {'content': \"i'm extremely irritated of most bugs, like when i was last camping i was a total nervous wreck because of all the horseflies, or when a spider appears descending right above me when i'm relaxing in...\", 'role': 'assistant'}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "ds = small_datasets.map(convert_to_chatml)\n",
    "print(ds[\"train\"][0][\"messages\"])\n",
    "\n",
    "messages = ds[\"train\"][0][\"messages\"]\n",
    "\n",
    "text = qwen_tokenizer.applychat_template(\n",
    "    messages,\n",
    "    tokenize = False,\n",
    "    add_generation_prompt = True\n",
    ")\n",
    "\n",
    "model_inputs = qwen_tokenizer([text]), return_tensors = \"pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b96e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = SFTConfig(\n",
    "    output_dir = \"./mbti_test_output\",\n",
    "    max_steps = 100,\n",
    "    per_device_train_batch_size = 1,\n",
    "    learning_rate = 5e-5,\n",
    "    logging_steps = 10,\n",
    "    save_steps=100,\n",
    "    eval_strategy = \"steps\",\n",
    "    eval_steps = 50,\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e88c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = SFTTrainer(\n",
    "    model=qwen_checkpoint,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    dataset_text_field = \"messages\",\n",
    "    processing_class=qwen_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a9118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_chatml(data):\n",
    "    \n",
    "    prompt = f\"Your personality Type is {data['label']}. What is on your mind?\"\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "            {\"role\": \"assistant\", \"content\": data[\"post\"]}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "ds = small_datasets.map(convert_to_chatml)\n",
    "# print(ds[\"train\"][0][\"messages\"])\n",
    "\n",
    "# messages = ds[\"train\"][0][\"messages\"]\n",
    "\n",
    "# text = qwen_tokenizer.apply_chat_template(\n",
    "#     messages,\n",
    "#     tokenize = False,\n",
    "#     add_generation_prompt = True\n",
    "# )\n",
    "\n",
    "#model_inputs = qwen_tokenizer([text], return_tensors = \"pt\")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir = \"./mbti_test_output\",\n",
    "    max_steps = 100,\n",
    "    per_device_train_batch_size = 1,\n",
    "    learning_rate = 5e-5,\n",
    "    logging_steps = 10,\n",
    "    save_steps=100,\n",
    "    eval_strategy = \"steps\",\n",
    "    eval_steps = 50,\n",
    "    fp16=True\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=qwen_checkpoint,\n",
    "    args=training_args,\n",
    "    train_dataset=ds[\"train\"],\n",
    "    eval_dataset=ds[\"validation\"],\n",
    "    dataset_text_field = \"messages\",\n",
    "    processing_class=qwen_tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
